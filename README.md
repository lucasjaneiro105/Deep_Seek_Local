<div align="center">
  <img src="https://github.com/user-attachments/assets/3a0be532-c518-47c8-98bb-510a49c22ee3" alt="image" />
</div>

# Deep_Seek_Localüêãü§ñ
Sistema de chat simples desenvolvido com Langchain, Ollama e Streamlit, permitindo intera√ß√£o via chat com o usu√°rio. Utiliza o modelo **deepseek-r1:1.5b**, que, mesmo sendo pequeno, demonstra √≥timos resultados.

## Vis√£o Geral‚öôÔ∏è
Este projeto √© um chatbot local que utiliza tecnologias como Langchain, Ollama e Streamlit para criar uma conversa√ß√£o fluida e eficiente. Ideal para quem busca uma solu√ß√£o simples e funcional para intera√ß√µes via chat.

## Caracter√≠sticas Principais
- Funciona totalmente offline, sem necessidade de conex√£o com a internet.
- Interface amig√°vel e f√°cil de usar, desenvolvida com Streamlit.
- Integra√ß√£o com modelos de linguagem via Ollama.

## Limita√ß√µes
- O modelo **deepseek-r1:1.5b**, por ser pequeno, pode apresentar respostas mais precisas em ingl√™s do que em outros idiomas.
- A gera√ß√£o de respostas pode ser um pouco lenta, dependendo do hardware utilizado.

## Como Executar
1. **Instale o Ollama**: Baixe e configure o Ollama no seu sistema.
2. **Baixe o modelo**: Utilize o comando `ollama pull deepseek-r1:1.5b` para baixar o modelo de interesse.
3. **Instale as depend√™ncias**: Execute `pip install -r requirements.txt` para instalar as bibliotecas necess√°rias.
4. **Clone o reposit√≥rio**: Fa√ßa o clone do projeto para o seu computador.
5. **Execute o chat**: Rode o comando `streamlit run chat.py` para iniciar o chatbot.
